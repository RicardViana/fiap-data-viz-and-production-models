{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89d6ca84",
   "metadata": {},
   "source": [
    "#### **An√°lise de neg√≥cios**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4580d69f",
   "metadata": {},
   "source": [
    "#### **Observa√ß√µes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd59115f",
   "metadata": {},
   "source": [
    "#### **Conte√∫do - Bases e Notebook da aula**\n",
    "\n",
    "Github:  \n",
    "\n",
    "https://github.com/FIAP/Pos_Tech_DTAT/tree/Analise-de-Negocios/Analise%20de%20Negocios  \n",
    "\n",
    "S√©rie Hist√≥rica de Pre√ßos de Combust√≠veis e de GLP:  \n",
    "\n",
    "https://www.gov.br/anp/pt-br/centrais-de-conteudo/dados-abertos/serie-historica-de-precos-de-combustiveis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a770d68e",
   "metadata": {},
   "source": [
    "#### **Importa√ß√£o de pacotes e bibliotecas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e53e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar biblioteca completa\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import zipfile  \n",
    "import io       \n",
    "import time\n",
    "import concurrent.futures\n",
    "import psycopg2 \n",
    "import csv\n",
    "\n",
    "# Importar algo especifico de uma biblioteca\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine, text\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21512f93",
   "metadata": {},
   "source": [
    "#### **Fun√ß√µes (def)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e6dc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontrar_links(soup):\n",
    "    \n",
    "    \"\"\"\n",
    "    Encontra dinamicamente os links de download na se√ß√£o \n",
    "    'Combust√≠veis automotivos'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Encontra o cabe√ßalho <h3> que cont√©m o texto \"Combust√≠veis automotivos\"\n",
    "    heading = soup.find(lambda tag: tag.name == 'h3' and 'Combust√≠veis automotivos' in tag.get_text())\n",
    "    \n",
    "    links_para_baixar = []\n",
    "    \n",
    "    if not heading:\n",
    "        print(\"Erro: N√£o foi poss√≠vel encontrar a se√ß√£o 'Combust√≠veis automotivos' no HTML da p√°gina\")\n",
    "        return links_para_baixar\n",
    "\n",
    "    # A lista <ul> com os links √© o pr√≥ximo \"irm√£o\" (sibling) da tag <h3>\n",
    "    ul_tag = heading.find_next_sibling('ul')\n",
    "    \n",
    "    if not ul_tag:\n",
    "        print(\"Erro: N√£o foi poss√≠vel encontrar a lista <ul> ap√≥s o cabe√ßalho\")\n",
    "        return links_para_baixar\n",
    "\n",
    "    # Encontra todas as tags <a> (links) dentro desta lista <ul>\n",
    "    a_tags = ul_tag.find_all('a')\n",
    "    \n",
    "    for a_tag in a_tags:\n",
    "        url = a_tag.get('href')\n",
    "        if url:\n",
    "            links_para_baixar.append(url)\n",
    "            \n",
    "    return links_para_baixar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaa7c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processar_arquivo(url, pasta_destino, max_retries, retry_delay):\n",
    "\n",
    "    \"\"\"\n",
    "    Baixa um arquivo com retentativas. Se for .zip, extrai. Se .csv, salva.\n",
    "    RETORNA uma string de status em vez de imprimir.\n",
    "    \"\"\"\n",
    "\n",
    "    nome_arquivo = os.path.basename(url)\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            \n",
    "            if nome_arquivo.endswith('.zip'):\n",
    "                response = requests.get(url) \n",
    "                response.raise_for_status()\n",
    "                \n",
    "                with zipfile.ZipFile(io.BytesIO(response.content)) as zf:\n",
    "                    zf.extractall(pasta_destino)\n",
    "                    nomes_extraidos = zf.namelist()\n",
    "                \n",
    "                return f\"[EXTRA√çDO] {nome_arquivo} -> {', '.join(nomes_extraidos)}\"\n",
    "\n",
    "            else:\n",
    "                caminho_local = os.path.join(pasta_destino, nome_arquivo)\n",
    "                \n",
    "                with requests.get(url, stream=True) as r:\n",
    "                    r.raise_for_status()\n",
    "                    with open(caminho_local, 'wb') as f:\n",
    "                        for chunk in r.iter_content(chunk_size=8192): \n",
    "                            f.write(chunk)\n",
    "                            \n",
    "                return f\"[SALVO] {nome_arquivo}\"\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            if attempt + 1 < max_retries:\n",
    "                time.sleep(retry_delay)\n",
    "            else: \n",
    "                return f\"[FALHA-REDE] {nome_arquivo} ap√≥s {max_retries} tentativas. Erro: {e}\"\n",
    "        \n",
    "        except zipfile.BadZipFile:\n",
    "            return f\"[FALHA-ZIP] {nome_arquivo} est√° corrompido ou n√£o √© .zip.\"\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"[FALHA-INESPERADA] {nome_arquivo}. Erro: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31131aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testar a conex√£o ao banco de dados\n",
    "def test_connection(engine):\n",
    "\n",
    "    try:\n",
    "        with engine.connect() as connection:\n",
    "            \n",
    "            # Testar a vers√£o do PostgreSQL\n",
    "            result = connection.execute(text(\"SELECT version();\"))\n",
    "            versao = result.fetchone()\n",
    "            print(\"‚úÖ Conectado com sucesso:\", versao[0])\n",
    "\n",
    "            # Listar as tabelas no schema p√∫blico\n",
    "            result = connection.execute(text(\"\"\"\n",
    "                SELECT table_name\n",
    "                FROM information_schema.tables\n",
    "                WHERE table_schema = 'anp';\n",
    "            \"\"\"))\n",
    "            tabelas = result.fetchall()\n",
    "            print(\"üìÑ Tabelas no banco:\")\n",
    "            for tabela in tabelas:\n",
    "                print(\"-\", tabela[0])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Erro ao executar comandos:\", e)\n",
    "        sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f06d05d",
   "metadata": {},
   "source": [
    "#### **Credenciais**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a0ff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Credenciais do PostgreSQL\n",
    "usuario_pg = os.getenv(\"POSTGRES_USER\")\n",
    "senha_pg = os.getenv(\"POSTGRES_PASSWORD\")\n",
    "host_pg = os.getenv(\"POSTGRES_HOST\")\n",
    "porta_pg = os.getenv(\"POSTGRES_PORT\")\n",
    "banco_pg = os.getenv(\"POSTGRES_DB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296ad762",
   "metadata": {},
   "source": [
    "#### **Variaveis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fa7654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N√∫mero m√°ximo de tentativas por arquivo\n",
    "max_retries = 5\n",
    "\n",
    "# Segundos de espera entre as tentativas\n",
    "retry_delay = 5  \n",
    "\n",
    "# Maximo de threads\n",
    "max_workers = 20\n",
    "\n",
    "# URL da p√°gina para extrair os links\n",
    "page_url = 'https://www.gov.br/anp/pt-br/centrais-de-conteudo/dados-abertos/serie-historica-de-precos-de-combustiveis'\n",
    "\n",
    "# Pasta onde os arquivos ser√£o baixados\n",
    "download_dir = 'arquivos_combustiveis_automotivos'\n",
    "\n",
    "# Validar download dos arquivos ANP\n",
    "baixar_arquivos_anp = 'n'\n",
    "\n",
    "# Nome do Schema e Tabela no banco de dados \n",
    "schema_db = 'anp'\n",
    "nome_tabela_db = 'preco_combustivel'\n",
    "nome_tabela_completo = f'{schema_db}.{nome_tabela_db}'\n",
    "\n",
    "# Chunksize para carga no banco de dados\n",
    "chunksize = 100000     \n",
    "\n",
    "# Validar carga no banco de dados\n",
    "carregar_tabela = 's' \n",
    "\n",
    "# Dicion√°rio para armazenar tempos\n",
    "tempos_execucao = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d70f28a",
   "metadata": {},
   "source": [
    "#### **Aula 1 - Processos e formas de an√°lise**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4ed4ab",
   "metadata": {},
   "source": [
    "#### **Aula 2 - Liga√ß√£o com bancos de dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737c07e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar engine com banco \n",
    "engine = create_engine(f\"postgresql+psycopg2://{usuario_pg}:{senha_pg}@{host_pg}:{porta_pg}/{banco_pg}\")\n",
    "\n",
    "# Testar a conex√£o\n",
    "test_connection(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598075b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixar os arquivos da ANP\n",
    "\n",
    "if baixar_arquivos_anp.lower() == 'n':\n",
    "    print(f'Etapa de carregar os dados do Github para o PostgreSQL n√£o realizada pois a variavel baixar_arquivos_anp √© `n`')\n",
    "    \n",
    "else:\n",
    "    start_extracao = time.perf_counter()\n",
    "\n",
    "    # 1. Criar a pasta de download\n",
    "    os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "    # 2. Baixar o HTML da p√°gina da ANP\n",
    "    print(f\"Acessando a p√°gina: {page_url}\")\n",
    "\n",
    "    try:\n",
    "        response = requests.get(page_url)\n",
    "        response.raise_for_status()\n",
    "        conteudo_html = response.text\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Erro fatal ao acessar a p√°gina da ANP: {e}\")\n",
    "        print(\"Verifique sua conex√£o com a internet ou se a URL da ANP mudou\")\n",
    "        sys.exit(1) \n",
    "\n",
    "    # 3. Analisar (parse) o HTML\n",
    "    soup = BeautifulSoup(conteudo_html, 'html.parser')\n",
    "\n",
    "    # 4. Encontrar os links\n",
    "    links = encontrar_links(soup)\n",
    "\n",
    "    if not links:\n",
    "        print(\"Nenhum link encontrado para baixar\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Encontrados {len(links)} arquivos para baixar na se√ß√£o 'Combust√≠veis automotivos'\")\n",
    "        print()\n",
    "\n",
    "        # 5. Processar (baixar ou extrair) cada arquivo EM PARALELO\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            print(f\"Iniciando downloads com at√© {max_workers} threads em paralelo...\")\n",
    "            print(\"-\" * 70)\n",
    "            future_to_url = {}\n",
    "\n",
    "            for url in links:\n",
    "                future = executor.submit(processar_arquivo, \n",
    "                                        url, \n",
    "                                        download_dir, \n",
    "                                        max_retries, \n",
    "                                        retry_delay)\n",
    "                \n",
    "                future_to_url[future] = url\n",
    "\n",
    "            num_concluidos = 0\n",
    "\n",
    "            for future in concurrent.futures.as_completed(future_to_url):\n",
    "                num_concluidos += 1\n",
    "                url = future_to_url[future]\n",
    "                \n",
    "                try:\n",
    "                    status_message = future.result()\n",
    "                    print(f\"({num_concluidos}/{len(links)}) {status_message}\")\n",
    "                    \n",
    "                except Exception as exc:\n",
    "                    print(f\"({num_concluidos}/{len(links)}) [FALHA-GERAL] {url} gerou uma exce√ß√£o: {exc}\")\n",
    "                    \n",
    "        print(\"-\" * 70)\n",
    "        print()\n",
    "        print(\"Download e processamento de todos os arquivos conclu√≠do\")\n",
    "        print(f\"Os arquivos est√£o salvos em: {os.path.abspath(download_dir)}\")\n",
    "\n",
    "    end_extracao = time.perf_counter()\n",
    "    tempos_execucao['extracao'] = end_extracao - start_extracao\n",
    "\n",
    "if baixar_arquivos_anp.lower() == 'n':\n",
    "    tempos_execucao['extracao'] = 0.0\n",
    "    \n",
    "else:\n",
    "    tempos_execucao['extracao'] = end_extracao - start_extracao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223ce369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados no banco de dados \n",
    "\n",
    "start_carga = time.perf_counter()\n",
    "\n",
    "colunas_tabela_pg = [\n",
    "    'regiao', 'estado', 'municipio', 'revenda', 'cnpj', 'nome_rua', \n",
    "    'numero_rua', 'complemento', 'bairro', 'cep', 'produto', \n",
    "    'data_coleta', 'valor_venda', 'unidade_medida', 'bandeira',\n",
    "    'nome_arquivo'\n",
    "]\n",
    "\n",
    "colunas_sql_copy = ', '.join(f'\\\"{col}\\\"' for col in colunas_tabela_pg) \n",
    "\n",
    "mapeamento_colunas_csv_para_pg = {\n",
    "    'Regiao - Sigla': 'regiao', 'Estado - Sigla': 'estado', 'Municipio': 'municipio',\n",
    "    'Revenda': 'revenda', 'CNPJ da Revenda': 'cnpj', 'Nome da Rua': 'nome_rua',\n",
    "    'Numero Rua': 'numero_rua', 'Complemento': 'complemento', 'Bairro': 'bairro',\n",
    "    'Cep': 'cep', 'Produto': 'produto', 'Data da Coleta': 'data_coleta',\n",
    "    'Valor de Venda': 'valor_venda', 'Unidade de Medida': 'unidade_medida',\n",
    "    'Bandeira': 'bandeira'\n",
    "}\n",
    "\n",
    "conn_str_psycopg = f\"dbname='{banco_pg}' user='{usuario_pg}' password='{senha_pg}' host='{host_pg}' port='{porta_pg}'\"\n",
    "\n",
    "if carregar_tabela.lower() == 'n':\n",
    "    print(f'Etapa de carregar os dados para o PostgreSQL n√£o realizada pois a variavel carregar_tabela √© `n`')\n",
    "\n",
    "else:\n",
    "    print(f\"Iniciando prepara√ß√£o do banco de dados para a tabela '{nome_tabela_completo}'\")\n",
    "    \n",
    "    sql_create_schema = text(f\"CREATE SCHEMA IF NOT EXISTS {schema_db};\")\n",
    "    sql_drop_table = text(f\"DROP TABLE IF EXISTS {nome_tabela_completo};\")\n",
    "    \n",
    "    sql_create_table = text(f\"\"\"\n",
    "        CREATE TABLE {nome_tabela_completo} (\n",
    "            regiao VARCHAR(255),\n",
    "            estado VARCHAR(255),\n",
    "            municipio VARCHAR(255),\n",
    "            revenda VARCHAR(255),\n",
    "            cnpj VARCHAR(255),\n",
    "            nome_rua VARCHAR(255),\n",
    "            numero_rua VARCHAR(255),\n",
    "            complemento VARCHAR(255),\n",
    "            bairro VARCHAR(255),\n",
    "            cep VARCHAR(255),\n",
    "            produto VARCHAR(255),\n",
    "            data_coleta DATE,\n",
    "            valor_venda FLOAT,\n",
    "            unidade_medida VARCHAR(255),\n",
    "            bandeira VARCHAR(255),\n",
    "            nome_arquivo VARCHAR(255),\n",
    "            data_carga TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "            usuario VARCHAR(255) DEFAULT CURRENT_USER\n",
    "        );\n",
    "    \"\"\")\n",
    "\n",
    "    try:\n",
    "        with engine.connect() as connection:\n",
    "            print(f\"Executando: CREATE SCHEMA IF NOT EXISTS {schema_db}\")\n",
    "            connection.execute(sql_create_schema)\n",
    "            print(f\"Executando: DROP TABLE IF EXISTS {nome_tabela_completo}\")\n",
    "            connection.execute(sql_drop_table)\n",
    "            print(f\"Executando: CREATE TABLE {nome_tabela_completo}\")\n",
    "            connection.execute(sql_create_table)\n",
    "            connection.commit() \n",
    "        print(\"‚úÖ Schema e Tabela recriados com sucesso no banco de dados\")\n",
    "\n",
    "    except Exception as e_sql:\n",
    "        print(f\"‚ùå Erro ao preparar o banco de dados com SQLAlchemy: {e_sql}\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    print(f\"\\nIniciando carga de dados via COPY para a tabela '{nome_tabela_completo}' a partir de '{download_dir}'\")\n",
    "    \n",
    "    conn_psycopg = None \n",
    "    cursor = None       \n",
    "    \n",
    "    try:\n",
    "        print(\"Conectando ao PostgreSQL via psycopg2...\")\n",
    "        conn_psycopg = psycopg2.connect(conn_str_psycopg)\n",
    "        conn_psycopg.autocommit = False \n",
    "        cursor = conn_psycopg.cursor()\n",
    "        print(\"‚úÖ Conectado com sucesso\")\n",
    "\n",
    "        print()\n",
    "        print(\"-\" * 70)\n",
    "        print(f\"Procurando arquivos .csv em '{download_dir}'\")\n",
    "        arquivos_csv = sorted([f for f in os.listdir(download_dir) if f.endswith('.csv')]) \n",
    "        \n",
    "        if not arquivos_csv:\n",
    "             print(\"Nenhum arquivo .csv encontrado na pasta e carga n√£o realizada\")\n",
    "\n",
    "        else:\n",
    "            print(f\"Encontrados {len(arquivos_csv)} arquivos .csv e iniciando carga via COPY\")\n",
    "            arquivos_processados = 0\n",
    "            arquivos_com_erro = 0\n",
    "\n",
    "            for nome_arquivo_csv in arquivos_csv:\n",
    "                caminho_completo = os.path.join(download_dir, nome_arquivo_csv)\n",
    "                print(f\"\\n--- Processando arquivo: {nome_arquivo_csv} ({arquivos_processados + arquivos_com_erro + 1}/{len(arquivos_csv)}) ---\")\n",
    "                \n",
    "                encodings_to_try = ['utf-8', 'latin-1']\n",
    "                detected_encoding = None\n",
    "\n",
    "                print(f\"Iniciando detec√ß√£o de encoding (tentando {encodings_to_try})\")\n",
    "                for encoding_attempt in encodings_to_try:\n",
    "                    try:\n",
    "                        pd.read_csv(\n",
    "                            caminho_completo, \n",
    "                            sep=';',              \n",
    "                            encoding=encoding_attempt, \n",
    "                            decimal=',',\n",
    "                            nrows=5 \n",
    "                        )\n",
    "\n",
    "                        print(f\"Sucesso: Encoding detectado como '{encoding_attempt}'\")\n",
    "                        detected_encoding = encoding_attempt\n",
    "                        break \n",
    "                    \n",
    "                    except UnicodeDecodeError:\n",
    "                        print(f\"Falha ao decodificar com '{encoding_attempt}' e tentando o pr√≥ximo\")\n",
    "                        continue\n",
    "                    \n",
    "                    except FileNotFoundError:\n",
    "                         print(f\"ERRO FATAL: Arquivo {nome_arquivo_csv} n√£o encontrado\")\n",
    "                         raise\n",
    "                    \n",
    "                    except Exception as e_detect:\n",
    "                        print(f\"Erro inesperado ao tentar ler com {encoding_attempt}: {e_detect}\")\n",
    "                        raise\n",
    "                \n",
    "                if detected_encoding is None:\n",
    "                    print(f\"ERRO FATAL: N√£o foi poss√≠vel decodificar o arquivo {nome_arquivo_csv} com nenhum encoding testado ({encodings_to_try})\")\n",
    "                    arquivos_com_erro += 1\n",
    "                    continue \n",
    "\n",
    "                try:\n",
    "                    chunk_iterator = pd.read_csv(\n",
    "                        caminho_completo, \n",
    "                        chunksize=chunksize, \n",
    "                        low_memory=False, \n",
    "                        sep=';',              \n",
    "                        encoding=detected_encoding,\n",
    "                        decimal=',',          \n",
    "                        parse_dates=['Data da Coleta'], \n",
    "                        dayfirst=True         \n",
    "                    )\n",
    "                \n",
    "                    total_chunks = 0\n",
    "\n",
    "                    for i, chunk in enumerate(chunk_iterator):\n",
    "                        total_chunks = i + 1\n",
    "                        \n",
    "                        try:\n",
    "                            chunk_renamed = chunk.rename(columns=mapeamento_colunas_csv_para_pg)\n",
    "\n",
    "                        except Exception as e_rename:\n",
    "                            print(f\"ERRO ao renomear colunas no chunk {total_chunks}: {e_rename}\")\n",
    "                            raise \n",
    "\n",
    "                        chunk_reordered = chunk_renamed.reindex(columns=colunas_tabela_pg)\n",
    "                        chunk_reordered['nome_arquivo'] = nome_arquivo_csv\n",
    "\n",
    "                        buffer = io.StringIO()\n",
    "                        chunk_reordered.to_csv(buffer, index=False, header=False, sep=',', \n",
    "                                               na_rep='\\\\N', quoting=csv.QUOTE_MINIMAL, \n",
    "                                               date_format='%Y-%m-%d')\n",
    "                        buffer.seek(0) \n",
    "\n",
    "                        print(f\"Carregando chunk {total_chunks}\")\n",
    "                        sql_copy_command = f\"\"\"COPY {nome_tabela_completo} ({colunas_sql_copy}) FROM STDIN WITH (FORMAT CSV, HEADER FALSE, NULL '\\\\N', DELIMITER ',')\"\"\"\n",
    "                        cursor.copy_expert(sql_copy_command, buffer)\n",
    "                        \n",
    "                    print(f\"Arquivo {nome_arquivo_csv} carregado ({total_chunks} chunks)\")\n",
    "                    conn_psycopg.commit() \n",
    "                    arquivos_processados += 1\n",
    "\n",
    "                except pd.errors.EmptyDataError:\n",
    "                    print(f\"AVISO: Arquivo {nome_arquivo_csv} est√° vazio ou tornou-se vazio ap√≥s leitura\")\n",
    "                    conn_psycopg.rollback() \n",
    "                    arquivos_com_erro += 1 \n",
    "\n",
    "                except FileNotFoundError: \n",
    "                    print(f\"‚ùå Erro: Arquivo {nome_arquivo_csv} n√£o encontrado durante processamento dos chunks\")\n",
    "                    conn_psycopg.rollback()\n",
    "                    arquivos_com_erro += 1\n",
    "\n",
    "                except Exception as e_file:\n",
    "                    print(f\"‚ùå Erro ao processar o arquivo {nome_arquivo_csv} (no chunk {total_chunks}): {e_file}\")\n",
    "                    print(f\"Verifique o mapeamento, tipos de dados (especialmente datas e decimais).\")\n",
    "                    conn_psycopg.rollback() \n",
    "                    arquivos_com_erro += 1\n",
    "            \n",
    "            print(\"-\" * 70)\n",
    "            print(f\"\\n‚úÖ Carga via COPY conclu√≠da\")\n",
    "            print(f\"Arquivos processados com sucesso: {arquivos_processados}\")\n",
    "            print(f\"Arquivos com erro/vazios: {arquivos_com_erro}\")\n",
    "\n",
    "    except psycopg2.Error as db_err:\n",
    "        print(f\"‚ùå Erro de conex√£o ou execu√ß√£o no PostgreSQL (psycopg2): {db_err}\")\n",
    "        if conn_psycopg:\n",
    "            conn_psycopg.rollback() \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro inesperado durante a carga dos dados (possivelmente ao iniciar leitura de {nome_arquivo_csv}): {e}\")\n",
    "        if conn_psycopg:\n",
    "            conn_psycopg.rollback()\n",
    "            \n",
    "    finally:\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "        if conn_psycopg:\n",
    "            conn_psycopg.close()\n",
    "            print(\"\\nConex√£o psycopg2 fechada\")\n",
    "            \n",
    "    print(\"\\nProcesso de carga finalizado\")\n",
    "\n",
    "    end_carga = time.perf_counter()\n",
    "    tempo_total_celula_carga = end_carga - start_carga\n",
    "\n",
    "if carregar_tabela.lower() == 'n':\n",
    "    tempos_execucao['carga'] = 0.0\n",
    "    \n",
    "else:\n",
    "    tempos_execucao['carga'] = tempo_total_celula_carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc5b741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumo da execu√ß√£o da extra√ß√£o e carregamento\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_616fc th.row_heading {\n",
       "  text-align: left;\n",
       "  min-width: 220px;\n",
       "}\n",
       "#T_616fc th.col_heading {\n",
       "  text-align: right;\n",
       "}\n",
       "#T_616fc_row0_col0, #T_616fc_row0_col1, #T_616fc_row1_col0, #T_616fc_row1_col1 {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_616fc\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_616fc_level0_col0\" class=\"col_heading level0 col0\" >Tempo (s)</th>\n",
       "      <th id=\"T_616fc_level0_col1\" class=\"col_heading level0 col1\" >Percentual (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_616fc_level0_row0\" class=\"row_heading level0 row0\" >Opera√ß√£o de Extra√ß√£o</th>\n",
       "      <td id=\"T_616fc_row0_col0\" class=\"data row0 col0\" >0.00</td>\n",
       "      <td id=\"T_616fc_row0_col1\" class=\"data row0 col1\" >0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_616fc_level0_row1\" class=\"row_heading level0 row1\" >Opera√ß√£o de Carga</th>\n",
       "      <td id=\"T_616fc_row1_col0\" class=\"data row1 col0\" >12.26</td>\n",
       "      <td id=\"T_616fc_row1_col1\" class=\"data row1 col1\" >100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17abb63c7d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ddb52 th.row_heading {\n",
       "  text-align: left;\n",
       "  min-width: 220px;\n",
       "}\n",
       "#T_ddb52 th.col_heading {\n",
       "  text-align: right;\n",
       "}\n",
       "#T_ddb52_row0_col0, #T_ddb52_row0_col1 {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ddb52\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ddb52_level0_col0\" class=\"col_heading level0 col0\" >Tempo (s)</th>\n",
       "      <th id=\"T_ddb52_level0_col1\" class=\"col_heading level0 col1\" >Percentual (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ddb52_level0_row0\" class=\"row_heading level0 row0\" >Tempo Total</th>\n",
       "      <td id=\"T_ddb52_row0_col0\" class=\"data row0 col0\" >12.26</td>\n",
       "      <td id=\"T_ddb52_row0_col1\" class=\"data row0 col1\" >100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17abb63c410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gerar resumo\n",
    "\n",
    "print(f\"Resumo da execu√ß√£o da extra√ß√£o e carregamento\\n\")\n",
    "\n",
    "tempo_extracao = tempos_execucao.get('extracao', 0.0)\n",
    "tempo_carga = tempos_execucao.get('carga', 0.0)\n",
    "\n",
    "if tempo_extracao == 0.0 and tempo_carga == 0.0:\n",
    "    print(\"Nenhuma opera√ß√£o (extra√ß√£o ou carga) foi cronometrada\")\n",
    "    \n",
    "elif (tempo_extracao + tempo_carga) == 0.0:\n",
    "     print(\"Tempo total foi zero e n√£o √© poss√≠vel calcular percentuais\")\n",
    "     \n",
    "else:\n",
    "    total_time = tempo_extracao + tempo_carga\n",
    "    perc_extracao = (tempo_extracao / total_time) * 100\n",
    "    perc_carga = (tempo_carga / total_time) * 100\n",
    "\n",
    "    data_ops = {\n",
    "        'Tempo (s)': [tempo_extracao, tempo_carga],\n",
    "        'Percentual (%)': [perc_extracao, perc_carga]\n",
    "    }\n",
    "\n",
    "    index_labels_ops = ['Opera√ß√£o de Extra√ß√£o', 'Opera√ß√£o de Carga']\n",
    "\n",
    "    df_ops = pd.DataFrame(data_ops, index=index_labels_ops)\n",
    "    \n",
    "    df_ops_styled = df_ops.style.format({\n",
    "        'Tempo (s)': '{:.2f}'.format,\n",
    "        'Percentual (%)': '{:.1f}'.format\n",
    "    }).set_properties(\n",
    "        **{'text-align': 'right'}\n",
    "    ).set_table_styles([\n",
    "        dict(selector=\"th.row_heading\", props=[(\"text-align\", \"left\"), (\"min-width\", \"220px\")]),\n",
    "        dict(selector=\"th.col_heading\", props=[(\"text-align\", \"right\")])\n",
    "    ])\n",
    "    \n",
    "    display(df_ops_styled)\n",
    "\n",
    "    data_total = {\n",
    "        'Tempo (s)': [total_time],\n",
    "        'Percentual (%)': [100.0]\n",
    "    }\n",
    "    index_labels_total = ['Tempo Total']\n",
    "    df_total = pd.DataFrame(data_total, index=index_labels_total)\n",
    "\n",
    "    df_total_styled = df_total.style.format({\n",
    "        'Tempo (s)': '{:.2f}'.format,\n",
    "        'Percentual (%)': '{:.1f}'.format\n",
    "    }).set_properties(\n",
    "        **{'text-align': 'right'}\n",
    "    ).set_table_styles([\n",
    "        dict(selector=\"th.row_heading\", props=[(\"text-align\", \"left\"), (\"min-width\", \"220px\")]),\n",
    "        dict(selector=\"th.col_heading\", props=[(\"text-align\", \"right\")])\n",
    "    ])\n",
    "\n",
    "    print()\n",
    "    display(df_total_styled)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
