{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89d6ca84",
   "metadata": {},
   "source": [
    "#### **Análise de negócios**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4580d69f",
   "metadata": {},
   "source": [
    "#### **Observações**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd59115f",
   "metadata": {},
   "source": [
    "#### **Conteúdo - Bases e Notebook da aula**\n",
    "\n",
    "Github:  \n",
    "\n",
    "https://github.com/FIAP/Pos_Tech_DTAT/tree/Analise-de-Negocios/Analise%20de%20Negocios  \n",
    "\n",
    "Série Histórica de Preços de Combustíveis e de GLP:  \n",
    "\n",
    "https://www.gov.br/anp/pt-br/centrais-de-conteudo/dados-abertos/serie-historica-de-precos-de-combustiveis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a770d68e",
   "metadata": {},
   "source": [
    "#### **Importação de pacotes e bibliotecas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7e53e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar biblioteca completa\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import zipfile  \n",
    "import io       \n",
    "import time\n",
    "import concurrent.futures\n",
    "\n",
    "# Importar algo especifico de uma biblioteca\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21512f93",
   "metadata": {},
   "source": [
    "#### **Funções (def)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3e6dc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontrar_links(soup):\n",
    "    \n",
    "    \"\"\"\n",
    "    Encontra dinamicamente os links de download na seção \n",
    "    'Combustíveis automotivos'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Encontra o cabeçalho <h3> que contém o texto \"Combustíveis automotivos\"\n",
    "    heading = soup.find(lambda tag: tag.name == 'h3' and 'Combustíveis automotivos' in tag.get_text())\n",
    "    \n",
    "    links_para_baixar = []\n",
    "    \n",
    "    if not heading:\n",
    "        print(\"Erro: Não foi possível encontrar a seção 'Combustíveis automotivos' no HTML da página\")\n",
    "        return links_para_baixar\n",
    "\n",
    "    # A lista <ul> com os links é o próximo \"irmão\" (sibling) da tag <h3>\n",
    "    ul_tag = heading.find_next_sibling('ul')\n",
    "    \n",
    "    if not ul_tag:\n",
    "        print(\"Erro: Não foi possível encontrar a lista <ul> após o cabeçalho\")\n",
    "        return links_para_baixar\n",
    "\n",
    "    # Encontra todas as tags <a> (links) dentro desta lista <ul>\n",
    "    a_tags = ul_tag.find_all('a')\n",
    "    \n",
    "    for a_tag in a_tags:\n",
    "        url = a_tag.get('href')\n",
    "        if url:\n",
    "            links_para_baixar.append(url)\n",
    "            \n",
    "    return links_para_baixar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccaa7c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processar_arquivo(url, pasta_destino, max_retries, retry_delay):\n",
    "\n",
    "    \"\"\"\n",
    "    Baixa um arquivo com retentativas. Se for .zip, extrai. Se .csv, salva.\n",
    "    RETORNA uma string de status em vez de imprimir.\n",
    "    \"\"\"\n",
    "\n",
    "    nome_arquivo = os.path.basename(url)\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            \n",
    "            if nome_arquivo.endswith('.zip'):\n",
    "                response = requests.get(url) \n",
    "                response.raise_for_status()\n",
    "                \n",
    "                with zipfile.ZipFile(io.BytesIO(response.content)) as zf:\n",
    "                    zf.extractall(pasta_destino)\n",
    "                    nomes_extraidos = zf.namelist()\n",
    "                \n",
    "                return f\"[EXTRAÍDO] {nome_arquivo} -> {', '.join(nomes_extraidos)}\"\n",
    "\n",
    "            else:\n",
    "                caminho_local = os.path.join(pasta_destino, nome_arquivo)\n",
    "                \n",
    "                with requests.get(url, stream=True) as r:\n",
    "                    r.raise_for_status()\n",
    "                    with open(caminho_local, 'wb') as f:\n",
    "                        for chunk in r.iter_content(chunk_size=8192): \n",
    "                            f.write(chunk)\n",
    "                            \n",
    "                return f\"[SALVO] {nome_arquivo}\"\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            if attempt + 1 < max_retries:\n",
    "                time.sleep(retry_delay)\n",
    "            else: \n",
    "                return f\"[FALHA-REDE] {nome_arquivo} após {max_retries} tentativas. Erro: {e}\"\n",
    "        \n",
    "        except zipfile.BadZipFile:\n",
    "            return f\"[FALHA-ZIP] {nome_arquivo} está corrompido ou não é .zip.\"\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"[FALHA-INESPERADA] {nome_arquivo}. Erro: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f06d05d",
   "metadata": {},
   "source": [
    "#### **Credenciais**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42a0ff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Credenciais do PostgreSQL\n",
    "usuario_pg = os.getenv(\"POSTGRES_USER\")\n",
    "senha_pg = os.getenv(\"POSTGRES_PASSWORD\")\n",
    "host_pg = os.getenv(\"POSTGRES_HOST\")\n",
    "porta_pg = os.getenv(\"POSTGRES_PORT\")\n",
    "banco_pg = os.getenv(\"POSTGRES_DB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296ad762",
   "metadata": {},
   "source": [
    "#### **Variaveis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fa7654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número máximo de tentativas por arquivo\n",
    "max_retries = 5\n",
    "\n",
    "# Segundos de espera entre as tentativas\n",
    "retry_delay = 5  \n",
    "\n",
    "# Maximo de threads\n",
    "max_workers = 20\n",
    "\n",
    "# URL da página para extrair os links\n",
    "page_url = 'https://www.gov.br/anp/pt-br/centrais-de-conteudo/dados-abertos/serie-historica-de-precos-de-combustiveis'\n",
    "\n",
    "# Pasta onde os arquivos serão baixados\n",
    "download_dir = 'arquivos_combustiveis_automotivos'\n",
    "\n",
    "# Validar download dos arquivos ANP\n",
    "baixar_arquivos_anp = 'n'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d70f28a",
   "metadata": {},
   "source": [
    "#### **Aula 1 - Processos e formas de análise**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4ed4ab",
   "metadata": {},
   "source": [
    "#### **Aula 2 - Ligação com bancos de dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598075b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acessando a página: https://www.gov.br/anp/pt-br/centrais-de-conteudo/dados-abertos/serie-historica-de-precos-de-combustiveis\n",
      "Encontrados 43 arquivos para baixar na seção 'Combustíveis automotivos'\n",
      "\n",
      "Iniciando downloads com até 20 threads em paralelo...\n",
      "----------------------------------------------------------------------\n",
      "(1/43) [EXTRAÍDO] ca-2023-02.zip -> Preços semestrais - AUTOMOTIVOS_2023.02.csv\n",
      "(2/43) [EXTRAÍDO] precos-semestrais-ca.zip -> precos-semestrais-ca-2022-01.csv\n",
      "(3/43) [EXTRAÍDO] ca-2022-02.zip -> ca-2022-02.csv\n",
      "(4/43) [EXTRAÍDO] ca-2023-01.zip -> Preços semestrais - AUTOMOTIVOS_2023.01.csv\n",
      "(5/43) [EXTRAÍDO] ca-2024-01.zip -> Preços semestrais - AUTOMOTIVOS_2024.01.csv\n",
      "(6/43) [EXTRAÍDO] ca-2025-01.zip -> Preços semestrais - AUTOMOTIVOS_2025.01.csv\n",
      "(7/43) [EXTRAÍDO] ca-2024-02.zip -> Preços semestrais - AUTOMOTIVOS_2024.02.csv\n",
      "(8/43) [SALVO] ca-2017-02.csv\n",
      "(9/43) [SALVO] ca-2015-02.csv\n",
      "(10/43) [SALVO] ca-2018-01.csv\n",
      "(11/43) [SALVO] ca-2019-02.csv\n",
      "(12/43) [SALVO] ca-2018-02.csv\n",
      "(13/43) [SALVO] ca-2016-02.csv\n",
      "(14/43) [SALVO] ca-2020-02.csv\n",
      "(15/43) [SALVO] ca-2014-02.csv\n",
      "(16/43) [SALVO] ca-2015-01.csv\n",
      "(17/43) [SALVO] ca-2012-02.csv\n",
      "(18/43) [SALVO] ca-2014-01.csv\n",
      "(19/43) [SALVO] ca-2021-01.csv\n",
      "(20/43) [SALVO] ca-2011-01.csv\n",
      "(21/43) [SALVO] ca-2012-01.csv\n",
      "(22/43) [SALVO] ca-2010-01.csv\n",
      "(23/43) [SALVO] ca-2009-02.csv\n",
      "(24/43) [SALVO] ca-2020-01.csv\n",
      "(25/43) [SALVO] ca-2017-01.csv\n",
      "(26/43) [SALVO] ca-2019-01.csv\n",
      "(27/43) [SALVO] ca-2004-01.csv\n",
      "(28/43) [SALVO] ca-2008-02.csv\n",
      "(29/43) [SALVO] ca-2005-02.csv\n",
      "(30/43) [SALVO] ca-2008-01.csv\n",
      "(31/43) [SALVO] ca-2011-02.csv\n",
      "(32/43) [SALVO] ca-2006-02.csv\n",
      "(33/43) [SALVO] ca-2005-01.csv\n",
      "(34/43) [SALVO] ca-2007-02.csv\n",
      "(35/43) [SALVO] ca-2010-02.csv\n",
      "(36/43) [SALVO] ca-2009-01.csv\n",
      "(37/43) [SALVO] ca-2021-02.csv\n",
      "(38/43) [SALVO] ca-2007-01.csv\n",
      "(39/43) [SALVO] ca-2006-01.csv\n",
      "(40/43) [SALVO] ca-2016-01.csv\n",
      "(41/43) [SALVO] ca-2013-02.csv\n",
      "(42/43) [SALVO] ca-2013-01.csv\n",
      "(43/43) [SALVO] ca-2004-02.csv\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Download e processamento de todos os arquivos concluído\n",
      "Os arquivos estão salvos em: c:\\Users\\ricar\\OneDrive\\Cursos\\Pós Graduação\\Data Analytics - FIAP\\06 - Fase 4 - Data Viz and Production Models\\arquivos_combustiveis_automotivos\n"
     ]
    }
   ],
   "source": [
    "# Baixar os arquivos da ANP\n",
    "\n",
    "if baixar_arquivos_anp.lower() == 'n':\n",
    "    print(f'Etapa de carregar os dados do Github para o PostgreSQL não realizada pois a variavel baixar_arquivos_anp é `n`')\n",
    "\n",
    "else:\n",
    "\n",
    "    # 1. Criar a pasta de download\n",
    "    os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "    # 2. Baixar o HTML da página da ANP\n",
    "    print(f\"Acessando a página: {page_url}\")\n",
    "\n",
    "    try:\n",
    "        response = requests.get(page_url)\n",
    "        response.raise_for_status()\n",
    "        conteudo_html = response.text\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Erro fatal ao acessar a página da ANP: {e}\")\n",
    "        print(\"Verifique sua conexão com a internet ou se a URL da ANP mudou\")\n",
    "        sys.exit(1) \n",
    "\n",
    "    # 3. Analisar (parse) o HTML\n",
    "    soup = BeautifulSoup(conteudo_html, 'html.parser')\n",
    "\n",
    "    # 4. Encontrar os links\n",
    "    links = encontrar_links(soup)\n",
    "\n",
    "    if not links:\n",
    "        print(\"Nenhum link encontrado para baixar\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Encontrados {len(links)} arquivos para baixar na seção 'Combustíveis automotivos'\")\n",
    "        print()\n",
    "\n",
    "        # 5. Processar (baixar ou extrair) cada arquivo EM PARALELO\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            print(f\"Iniciando downloads com até {max_workers} threads em paralelo...\")\n",
    "            print(\"-\" * 70)\n",
    "            future_to_url = {}\n",
    "\n",
    "            for url in links:\n",
    "                future = executor.submit(processar_arquivo, \n",
    "                                        url, \n",
    "                                        download_dir, \n",
    "                                        max_retries, \n",
    "                                        retry_delay)\n",
    "                \n",
    "                future_to_url[future] = url\n",
    "\n",
    "            num_concluidos = 0\n",
    "\n",
    "            for future in concurrent.futures.as_completed(future_to_url):\n",
    "                num_concluidos += 1\n",
    "                url = future_to_url[future]\n",
    "                \n",
    "                try:\n",
    "                    status_message = future.result()\n",
    "                    print(f\"({num_concluidos}/{len(links)}) {status_message}\")\n",
    "                    \n",
    "                except Exception as exc:\n",
    "                    print(f\"({num_concluidos}/{len(links)}) [FALHA-GERAL] {url} gerou uma exceção: {exc}\")\n",
    "                    \n",
    "        print(\"-\" * 70)\n",
    "        print()\n",
    "        print(\"Download e processamento de todos os arquivos concluído\")\n",
    "        print(f\"Os arquivos estão salvos em: {os.path.abspath(download_dir)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
